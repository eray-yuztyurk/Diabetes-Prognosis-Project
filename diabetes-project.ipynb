{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6972004,"sourceType":"datasetVersion","datasetId":4005869}],"dockerImageVersionId":30579,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/erayyuztyurk/diabetes-project?scriptVersionId=167702550\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# BUSINESS PROBLEM\n------------------------------------------------------------------------------------------------------------------------\nA machine learning model is requested to predict whether individuals have diabetes when their features are specified.\nBefore developing the model, it is expected that the necessary data analysis and feature engineering steps be performed.\n\n# DATASET STORY\n------------------------------------------------------------------------------------------------------------------------\nThe dataset is part of a large dataset maintained by the National Institute of Diabetes and Digestive and\nKidney Diseases in the United States. It consists of data used for diabetes research conducted on Pima Indian women\naged 21 and older living in Phoenix, the fifth-largest city in the state of Arizona, USA.\n\nThe target variable is defined as 'outcome,' where 1 indicates a positive diabetes test result, and 0 indicates\na negative result.\n\n# FEATURES\n------------------------------------------------------------------------------------------------------------------------\n#### Variable Names\n------------------------------------------------------------------------------------------------------------------------\n- **Pregnancies:**               Number of pregnancies\n- **Glucose:**                   2-hour plasma glucose concentration during an oral glucose tolerance test\n- **Blood Pressure:**            Diastolic blood pressure (mm Hg)\n- **Skin Thickness:**            Skinfold thickness (mm)\n- **Insulin:**                   2-hour serum insulin (mu U/ml)\n- **DiabetesPedigreeFunction:**  Diabetes pedigree function (2-hour plasma glucose concentration)\n- **BMI:**                       Body mass index (weight in kg / (height in m)^2)\n- **Age:**                       Age (years)\n- **Outcome:**                   Presence (1) or absence (0) of diabetes\n------------------------------------------------------------------------------------------------------------------------\n\n# PROJECT TASKS\n\n_The core focus of this project lies in feature engineering, where various techniques are applied to extract valuable insights from the dataset._\n\n------------------------------------------------------------------------------------------------------------------------\n#### Step 1: Exploratory Data Analysis\n- 1.1 - Examining the big picture.\n- 1.2 - Identifying numerical and categorical variables.\n- 1.3 - Analyzing numerical and categorical variables.\n- 1.4 - Conducting a target variable analysis.\n- 1.5 - Performing outlier analysis.\n- 1.6 - Performing missing data analysis.\n- 1.7 - Performing correlation analysis.\n\n#### Step 2: Feature Engineering\n- 2.1 - Performing necessary operations for missing and outlier values.\n- 2.2 - Creating new variables.\n- 2.3 - Performing encoding operations.\n- 2.4 - Standardizing numerical variables.\n\n#### Step 3: Modelling\n- 3.1 - K-Nearest Neighbors Model\n- 3.2 - RandomForestClassifier Model","metadata":{}},{"cell_type":"markdown","source":"# Importing required libraries and setting options","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.impute import KNNImputer\nfrom sklearn.neighbors import LocalOutlierFactor\nimport missingno as msno\n\npd.set_option(\"display.float_format\", lambda x: f\"{x:.4f}\")\npd.set_option(\"display.expand_frame_repr\", False)\npd.set_option(\"display.max_rows\",50)\n\ndef show_rows(show=False):\n    if show:\n        pd.set_option(\"display.max_rows\", None)\n    else:\n        pd.set_option(\"display.max_rows\", 50)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:58:55.046159Z","iopub.execute_input":"2024-03-18T22:58:55.047302Z","iopub.status.idle":"2024-03-18T22:58:55.056064Z","shell.execute_reply.started":"2024-03-18T22:58:55.047178Z","shell.execute_reply":"2024-03-18T22:58:55.054599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading Dataset","metadata":{}},{"cell_type":"code","source":"diabetes = pd.read_csv(\"/kaggle/input/diabetes/diabetes.csv\")\ndf = diabetes.copy()\ndf","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:58:55.086881Z","iopub.execute_input":"2024-03-18T22:58:55.087628Z","iopub.status.idle":"2024-03-18T22:58:55.125174Z","shell.execute_reply.started":"2024-03-18T22:58:55.087571Z","shell.execute_reply":"2024-03-18T22:58:55.124169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 1: Exploratory Data Analysis\n## 1.1 - Examine the big picture","metadata":{}},{"cell_type":"code","source":"def check_df(dataframe, show_value_counts = False):\n    import pandas as pd\n    pd.set_option(\"display.colheader_justify\",\"left\")\n    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------\")\n    print(\"-------- SHAPE of Dataset -----------------------------------------------------------------------------------------------------------------------\")\n    print(dataframe.shape)\n    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------\")\n    print(\"-------- DATA TYPES of Dataset ------------------------------------------------------------------------------------------------------------------\")\n    print(dataframe.dtypes)\n    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------\")\n    print(\"-------- MEMORY USAGE of Dataset --------------------------------------------------------------------------------------------------------------  \")\n    print(dataframe.memory_usage(deep=True) / (1024 * 1024), \"\\n (All are in MB)\")\n    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------\")\n    print(\"-------- MISSING VALUES in Dataset --------------------------------------------------------------------------------------------------------------\")\n    print(dataframe.isnull().sum())\n    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------\")\n    print(\"-------- DESCRIPTIVE Info about Dataset ---------------------------------------------------------------------------------------------------------\")\n    print(dataframe.describe([0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99]).T)\n    print(\"-------------------------------------------------------------------------------------------------------------------------------------------------\")\n\n    if show_value_counts:\n        print(\"-------- VALUE COUNTS in Dataset ----------------------------------------------------------------------------------------------------------------\")\n        for col in dataframe.columns:\n            print(dataframe[col].value_counts())\n            print(\"-------------------------------------------------------------------------------------------------------------------------------------------------\")","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-18T22:58:55.127397Z","iopub.execute_input":"2024-03-18T22:58:55.127852Z","iopub.status.idle":"2024-03-18T22:58:55.13937Z","shell.execute_reply.started":"2024-03-18T22:58:55.127822Z","shell.execute_reply":"2024-03-18T22:58:55.138054Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#- an overview for dataframe\ncheck_df(df, show_value_counts=False)\n#---------------------------------------------------------------------------------------------\ntarget_label = \"Outcome\"\n#---------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:58:55.141222Z","iopub.execute_input":"2024-03-18T22:58:55.141987Z","iopub.status.idle":"2024-03-18T22:58:55.18945Z","shell.execute_reply.started":"2024-03-18T22:58:55.141942Z","shell.execute_reply":"2024-03-18T22:58:55.188242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comments:\n- Target Label is \"Outcome\" and values are 0 and 1.\n- There is no NaN values.\n- There are many min 0 values which do not make sense and should not be 0 in normal circumstances (e.g. Glucose, BloodPressure, SkinThickness, Insulin, BMI)\n- There are skewed variables. But it can be deceptive as min value is 0 for above columns.\n- Kurtosis is not examined by choice (if desired, it is required statsmodels or manual calculation).\n- Accepted ranges for variables should be checked online for more info.","metadata":{}},{"cell_type":"markdown","source":"## 1.2 - Identify numerical and categorical variables.","metadata":{}},{"cell_type":"code","source":"def grab_column_names_based_on_types(dataframe, cardinal_threshold_percent=0.6, category_threshold_num=20):\n    def is_date(string):\n        from datetime import datetime as dt\n        import pandas as pd\n        try:\n            if dt.strptime(string, '%Y-%m-%d %H:%M:%S'):\n                return True\n            else:\n                return False\n        except ValueError:\n            return False\n    date_cols = [col for col in dataframe.columns if (dataframe[col].dtype in [\"O\"] and all(is_date(str(value)) for value in dataframe.dropna(subset=[col])[col]) or type(dataframe[col].iloc[0]) is pd.Timestamp)]\n    num_but_car_cols = [col for col in dataframe.columns if dataframe[col].dtype in [\"int\", \"float\"] and dataframe[col].nunique() == (dataframe.shape[0])]\n    cat_but_car_cols = [col for col in dataframe.columns if dataframe[col].dtype in [\"O\"] and dataframe[col].nunique() > (dataframe.shape[0] * cardinal_threshold_percent) and not col in date_cols]\n    car_cols = num_but_car_cols + cat_but_car_cols\n    num_but_cat_cols = [col for col in dataframe.columns if dataframe[col].dtype in [\"int\", \"float\"] and dataframe[col].nunique() < category_threshold_num]\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtype in [\"O\"] and not col in cat_but_car_cols and not col in date_cols] + num_but_cat_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtype in [\"int\", \"float\"] and not col in num_but_cat_cols and not col in num_but_car_cols]\n\n    print(\"------------------------------------------------------------------------------------------------------------\")\n    print(f\"Observations Count: {dataframe.shape[0]}\")\n    print(f\"Variables Count: {dataframe.shape[1]}\")\n    print(\"------------------------------------------------------------------------------------------------------------\")\n    print(f'Date Columns Count: {len(date_cols)} -> {date_cols}')\n    print(f'Numeric Columns Count: {len(num_cols)} -> {num_cols}')\n    print(f'Categorical Columns Count: {len(cat_cols)} -> {cat_cols}')\n    print(f'Cardinal Columns Count: {len(car_cols)} -> {car_cols}')\n    print(\"------------------------------------------------------------------------------------------------------------\")\n    print(f'Numeric but Cardinal Columns Count: {len(num_but_car_cols)} -> {num_but_car_cols}')\n    print(f'Numeric but Categorical Columns Count: {len(num_but_cat_cols)} -> {num_but_cat_cols}')\n    print(f'Categorical but Cardinal Columns Count: {len(num_but_cat_cols)} -> {cat_but_car_cols}')\n    print(\"------------------------------------------------------------------------------------------------------------\")\n    if dataframe.shape[1] == (len(date_cols) + len(num_cols) + len(cat_cols) + len(car_cols)):\n        print(f'Variables Count {dataframe.shape[1]} and Sum of Date,Numeric,Categorical and Cardinal Columns Counts {len(date_cols) + len(num_cols) + len(cat_cols) + len(car_cols)} are equal..')\n    else:\n        print(\n            f'Variables Count {dataframe.shape[1]} and Sum of Date,Numeric,Categorical and Cardinal Columns Counts {len(date_cols) + len(num_cols) + len(cat_cols) + len(car_cols)} are NOT equal !!')\n    print(\"------------------------------------------------------------------------------------------------------------\")\n    return num_cols, cat_cols, car_cols, date_cols","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-18T22:58:55.193113Z","iopub.execute_input":"2024-03-18T22:58:55.193954Z","iopub.status.idle":"2024-03-18T22:58:55.213466Z","shell.execute_reply.started":"2024-03-18T22:58:55.193905Z","shell.execute_reply":"2024-03-18T22:58:55.21209Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #- determine column datatypes\nnum_cols, cat_cols, car_cols, date_cols = grab_column_names_based_on_types(diabetes)\n#---------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:58:55.215303Z","iopub.execute_input":"2024-03-18T22:58:55.215876Z","iopub.status.idle":"2024-03-18T22:58:55.231863Z","shell.execute_reply.started":"2024-03-18T22:58:55.215828Z","shell.execute_reply":"2024-03-18T22:58:55.230464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comments:\n- There are 7 numerical and 2 categorical columns\n- Pregnancies is accepted as categorical.\n- Target Label is \"Outcome\" and values are 0 and 1.","metadata":{}},{"cell_type":"markdown","source":"## 1.3 - Analyze numerical and categorical variables.","metadata":{}},{"cell_type":"code","source":"def categoricals_summary(dataframe, column_name, plot=False):\n    print(pd.DataFrame({column_name: dataframe[column_name].value_counts(),\n                 \"Ratio\": 100 * (dataframe[column_name].value_counts() / len(dataframe))}))\n    print(\"--------------------------------------------------------------------------------------------------------\")\n\n    if plot:\n        sns.countplot(x=dataframe[column_name], data=dataframe)\n        plt.show()\ndef numericals_summary(dataframe, column_name, plot = False, plot_bins = 20):\n\n    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n    print(dataframe[column_name].describe(quantiles).T)\n\n    if plot:\n        dataframe[column_name].hist(bins = plot_bins)\n        plt.xlabel(column_name)\n        plt.title(column_name)\n        plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-18T22:58:55.23371Z","iopub.execute_input":"2024-03-18T22:58:55.234597Z","iopub.status.idle":"2024-03-18T22:58:55.246454Z","shell.execute_reply.started":"2024-03-18T22:58:55.234552Z","shell.execute_reply":"2024-03-18T22:58:55.245163Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #- analysis of categorical variables\nprint(\"---------------------------------------------\")\nprint(\"----- Analysis of Categorical Variables -----\")\nprint(\"---------------------------------------------\")\nfor col in cat_cols:\n    print(f\"----- {col} ---------------------------------------------------------------------\")\n    print(df.groupby(col).agg({target_label: [\"mean\", \"count\"]}))\n    print(\"----------------------------------------------------------------------------------\")\n    categoricals_summary(df, col, plot=True)\n#---------------------------------------------------------------------------------------------\n #- analysis of numerical variables\nprint(\"---------------------------------------------\")\nprint(\"----- Analysis of Numerical Variables -------\")\nprint(\"---------------------------------------------\")\nfor col in num_cols:\n    print(f\"----- {col} ---------------------------------------------------------------------\")\n    print(df.groupby(target_label).agg({col: [\"mean\", \"min\", \"max\"]}))\n    print(\"----------------------------------------------------------------------------------\")\n    numericals_summary(df, col, plot=True)\n#---------------------------------------------------------------------------------------------\nprint(\"---------------------------------------------\")\nprint(\"----- Boxplot Analysis ----------------------\")\nprint(\"---------------------------------------------\")\n #- box plots\nfor col in num_cols:\n    print(f\"----- {col} ---------------------------------------------------------------------\")\n    sns.boxplot(x=df[col],)\n    plt.show(block=True)\n    print(\"----------------------------------------------------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:58:55.248085Z","iopub.execute_input":"2024-03-18T22:58:55.248898Z","iopub.status.idle":"2024-03-18T22:59:01.147447Z","shell.execute_reply.started":"2024-03-18T22:58:55.248863Z","shell.execute_reply":"2024-03-18T22:59:01.146153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comments:\n- There are many variables with outliers.\n- Pregnancies: Variable is right skewed. Most of the values are positioned between 0-2. It seems cases above 10 are rare.\n- Outcome: In dataset, 1/3 of observations are as 1 and 2/3 of observation as 0 resulted.\n- Glucose: It seems that variable almost normally distributed. (except zeroes)\n- BloodPressure: It seems that variable is almost normally distributed. (except zeroes and approx. between 20-30)\n- SkinThickness: It seems that variable is almost normally distributed. (except zeroes and approx. between 0-10 and above 55)\n- Insulin: Variable is right skewed. Most of the values are positioned between 40-200. (except zeroes and approx. above 600)\n- BMI: It seems that variable is almost normally distributed (except zeroes and approx. above 50).\n- DiabetesPedigreeFunction: Variable is right skewed. Most of the values are positioned between 0.10-0.60. (except approx. above 1.50)\n- Age: Variable is right skewed. Most of the values are positioned between 20-50. (except approx. above 60)","metadata":{}},{"cell_type":"markdown","source":"## 1.4 - Conduct a target variable analysis. (Mean of the target variable by categorical variables and mean of numerical variables by the target variable)","metadata":{}},{"cell_type":"code","source":" #- analysis of categorical variables\nfor col in cat_cols:\n    print(f\"{col} ---------------------------------------------------------------------------\")\n    df_grouped = df.groupby(col).agg({target_label: [\"mean\", \"count\"]})\n    print(df_grouped.sort_values(by=(target_label, \"mean\"), ascending=False))\n    print(\"----------------------------------------------------------------------------------\")\n#---------------------------------------------------------------------------------------------\n #- analysis of numerical variables\nfor col in num_cols:\n    print(f\"{col} ---------------------------------------------------------------------------\")\n    df_grouped = df.groupby(target_label, group_keys=False).agg({col: [\"mean\", \"min\", \"max\"]})\n    print(df_grouped.sort_values(by=(col, \"mean\"), ascending=False))\n    print(\"----------------------------------------------------------------------------------\")\n#---------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:01.149489Z","iopub.execute_input":"2024-03-18T22:59:01.149861Z","iopub.status.idle":"2024-03-18T22:59:01.209235Z","shell.execute_reply.started":"2024-03-18T22:59:01.149827Z","shell.execute_reply":"2024-03-18T22:59:01.208113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comments:\n##### Categorical Variables\n- Pregnancies: \n-- Values between 0 and 3 have top frequencies in compare to others.\n-- Values between 7 and 13 are distinctive for Outcome with over 40 percent (not considering counts).\n-- Values between 14 and 17 are rare.\n-- There can be created new features with 4 categories -> (0-3), (4-6), (7-13), (14-17)\n- Outcome:     1/3 of observations are as 1 and 2/3 of observation as 0 resulted.\n\n##### Numerical variables\n- Glucose:     Glucose may be distinctive with 141.25 for 1 / 109.98 for 0. High glucose may cause positive result.\n- Insulin:     Insulin may be distinctive with 100.34 for 1 / 68.79 for 0. High insulin may cause positive result.\n- BMI:         BMI may be distinctive with 35.14 for 1 / 30.30 for 0. High BMI may cause positive result.","metadata":{}},{"cell_type":"markdown","source":"## 1.5 - Perform outlier analysis.","metadata":{}},{"cell_type":"code","source":"def outlier_thresholds(dataframe, column_name, q1 = 0.25, q3 = 0.75, print_info=True):\n    q1_num = dataframe[column_name].quantile(q1)\n    q3_num = dataframe[column_name].quantile(q3)\n    iqr = q3_num - q1_num\n    lower_threshold = q1_num - iqr * 1.5\n    upper_threshold = q3_num + iqr * 1.5\n    if print_info:\n        print(f\"for {column_name}:\")\n        print(f\"Q1 is {q1}\")\n        print(f\"Q3 is {q3}\")\n        print(f\"Q1 threshold is {q1_num}\")\n        print(f\"Q3 threshold is {q3_num}\")\n        print(f\"IQR is {iqr}\")\n        print(f\"Lower threshold is {lower_threshold}\")\n        print(f\"Upper Threshold is {upper_threshold}\")\n        print(\"-----------------------------------------------------------------------------------------------------------\")\n    return lower_threshold, upper_threshold\n#----------------------------------------------------------------------------------------------------------------------\ndef check_if_outlier_exists(dataframe, column_name, q1 = 0.25, q3 = 0.75, print_details=True):\n    low_limit, up_limit = outlier_thresholds(dataframe, column_name, q1, q3, print_details)\n    if dataframe[((dataframe[column_name] < low_limit) | (dataframe[column_name] > up_limit))].shape[0] > 0:\n        print(f\"{column_name} : Outliers exist based on Q1={q1} and Q3={q3}\")\n        print(f\"Under lower bound: {len(dataframe[dataframe[column_name] < low_limit])} observation of {len(dataframe)}\")\n        print(f\"Above upper bound: {len(dataframe[dataframe[column_name] > up_limit])} observation of {len(dataframe)}\")\n        print(\"-------------------------------------------------------------------------------------------------------\")\n        return True\n    else:\n        print(f\"{column_name} : No Outlier based on Q1={q1} and Q3={q3}\")\n        print(\"-------------------------------------------------------------------------------------------------------\")\n        return False\n#----------------------------------------------------------------------------------------------------------------------\ndef grap_outliers(dataframe, column_name, q1 = 0.25, q3 = 0.75, get_incides=False, print_results=True):\n\n    low_limit, up_limit = outlier_thresholds(dataframe, column_name, q1, q3)\n\n    if print_results:\n        if len(dataframe[(dataframe[column_name] < low_limit) | (dataframe[column_name] > up_limit)]) > 10:\n            print(dataframe[(dataframe[column_name] < low_limit) | (dataframe[column_name] > up_limit)].head())\n        else:\n            print(dataframe[(dataframe[column_name] < low_limit) | (dataframe[column_name] > up_limit)])\n\n    if get_incides:\n        return dataframe[(dataframe[column_name] < low_limit) | (dataframe[column_name] > up_limit)].index\n#----------------------------------------------------------------------------------------------------------------------\ndef rare_analyzer(dataframe, target_col_name, forCategoricals=True, forNumericals=False):\n    if forCategoricals:\n        for col in cat_cols:\n            print(f'{col} Count: {len(dataframe[col])}')\n            dff = pd.DataFrame({\"Count\": dataframe[col].value_counts(),\n                                \"Ratio\": dataframe[col].value_counts() / len(dataframe),\n                                \"Target_Mean\": dataframe.groupby(col)[target_col_name].mean()})\n            print(dff.sort_values(by=[\"Ratio\", \"Target_Mean\", \"Count\"], ascending=[False, False, False]))\n            print(\"-----------------------------------------------------------------------------------\")\n\n    if forNumericals:\n        for col in num_cols:\n            print(f'{col} Count: {len(dataframe[col])}')\n            dff = pd.DataFrame({\"Count\": dataframe[col].value_counts(),\n                                \"Ratio\": dataframe[col].value_counts() / len(dataframe),\n                                \"Target_Mean\": dataframe.groupby(col)[target_col_name].mean()})\n            print(dff.sort_values(by=[\"Ratio\", \"Target_Mean\", \"Count\"], ascending=[False, False, False]))\n            print(\"-----------------------------------------------------------------------------------\")\n#----------------------------------------------------------------------------------------------------------------------\ndef local_outlier_factor_analysis(dataframe, plot=False, return_scores= False, n_neighbors=20):\n    lof = LocalOutlierFactor(n_neighbors=n_neighbors)\n    lof.fit_predict(dataframe)\n    scores_neg = np.sort(lof.negative_outlier_factor_)\n    if plot:\n        pd.DataFrame(scores_neg).plot(stacked=True, xlim = [0,30], style=\".-\")\n        plt.show()\n    if return_scores:\n        return scores_neg","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-18T22:59:01.210939Z","iopub.execute_input":"2024-03-18T22:59:01.211424Z","iopub.status.idle":"2024-03-18T22:59:01.236845Z","shell.execute_reply.started":"2024-03-18T22:59:01.21138Z","shell.execute_reply":"2024-03-18T22:59:01.235652Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #- box plots\nprint(\"---------------------------------------------\")\nprint(\"----- Boxplot Analysis ----------------------\")\nprint(\"---------------------------------------------\")\n\nfor col in num_cols:\n    print(f\"----- {col} ---------------------------------------------------------------------\")\n    sns.boxplot(x=df[col],)\n    plt.show(block=True)\n    print(\"----------------------------------------------------------------------------------\")\n#---------------------------------------------------------------------------------------------\n #- check if any outlier exists\nprint(\"---------------------------------------------\")\nprint(\"----- Outlier Analysis ----------------------\")\nprint(\"---------------------------------------------\")\n\nfor col in df.columns:\n    check_if_outlier_exists(df, col, q1=0.25, q3=0.75)\n#---------------------------------------------------------------------------------------------\n\n #- check rarity of values\nprint(\"---------------------------------------------\")\nprint(\"----- Rare Analysis -------------------------\")\nprint(\"---------------------------------------------\")\nrare_analyzer(df, target_label, forNumericals=True)\n#---------------------------------------------------------------------------------------------\nprint(\"---------------------------------------------\")\nprint(\"----- LOF Analysis --------------------------\")\nprint(\"---------------------------------------------\")\n #- local factor analysis\nscores = local_outlier_factor_analysis(df, plot=True, return_scores=True)\nprint(f\" Based on LOF scores, threshold can be selected as {scores[10]}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:01.24311Z","iopub.execute_input":"2024-03-18T22:59:01.243649Z","iopub.status.idle":"2024-03-18T22:59:03.375057Z","shell.execute_reply.started":"2024-03-18T22:59:01.243603Z","shell.execute_reply":"2024-03-18T22:59:03.373829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comments:\n- There are many outliers if thresholds are chosen as 0.25 for Q1 and 0.75 for Q3.\n- They should be checked again after correction of 0 values in some features.\n- It can be created rare variable for Pregnancies between 14-17\n- for LOF, it seems that 10. value can be used as threshold for now (-1.7062264314830031)","metadata":{}},{"cell_type":"markdown","source":"## 1.6 - Perform missing data analysis.","metadata":{}},{"cell_type":"code","source":"def missing_values_summary(dataframe, print_df=True, return_na_col_names=False,return_na_df=False):\n    na_cols = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    na_list = dataframe[na_cols].isnull().sum().sort_values(ascending=False)\n    na_ratios = (dataframe[na_cols].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n    na_df = pd.DataFrame(na_ratios).reset_index().rename(columns={\"index\": \"NA_Column\", 0: \"Ratio\"})\n    if print_df:\n        if len(na_df) == 0:\n            print(\"There is no missing values in the dataset.\")\n        else:\n            print(na_df)\n\n    if return_na_col_names:\n        return na_cols\n\n    if return_na_df:\n        return na_df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-18T22:59:03.376735Z","iopub.execute_input":"2024-03-18T22:59:03.37709Z","iopub.status.idle":"2024-03-18T22:59:03.386228Z","shell.execute_reply.started":"2024-03-18T22:59:03.377057Z","shell.execute_reply":"2024-03-18T22:59:03.385006Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #- check for missing values\nmissing_values_summary(df)\n#---------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:03.387775Z","iopub.execute_input":"2024-03-18T22:59:03.388141Z","iopub.status.idle":"2024-03-18T22:59:03.408465Z","shell.execute_reply.started":"2024-03-18T22:59:03.388109Z","shell.execute_reply":"2024-03-18T22:59:03.407138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comments:\n- There is no missing values in the dataset but 0 values should be considered as NaN, then all should be checked again.","metadata":{}},{"cell_type":"markdown","source":"## 1.7 - Perform correlation analysis.","metadata":{}},{"cell_type":"code","source":"def correlation_matrix_for_numerical_variables(dataframe, numeric_columns, show_plot=True, return_corr_matrix=False):\n    print(\"-------- Correlation Mapping ---------\")\n    print(\"Very Weak Correlation:   (0.00 - 0.19)\")\n    print(\"Weak Correlation:        (0.20 - 0.39)\")\n    print(\"Moderate Correlation:    (0.40 - 0.59)\")\n    print(\"Strong Correlation:      (0.60 - 0.79)\")\n    print(\"Very Strong Correlation: (0.80 - 1.00)\")\n    print(\"--------------------------------------\")\n    corr_matrix = dataframe[numeric_columns].corr()\n    if show_plot:\n        sns.heatmap(corr_matrix, vmin=-1, vmax=1, cmap=\"RdBu\", annot=True)\n        plt.show()\n    if return_corr_matrix:\n        return corr_matrix","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:03.410214Z","iopub.execute_input":"2024-03-18T22:59:03.410646Z","iopub.status.idle":"2024-03-18T22:59:03.419926Z","shell.execute_reply.started":"2024-03-18T22:59:03.410605Z","shell.execute_reply":"2024-03-18T22:59:03.41881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" #- create correlation matrix of numerical variables\ncorrelation_matrix_for_numerical_variables(df, num_cols, show_plot=True)\n#---------------------------------------------------------------------------------------------","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:03.421268Z","iopub.execute_input":"2024-03-18T22:59:03.42167Z","iopub.status.idle":"2024-03-18T22:59:03.980031Z","shell.execute_reply.started":"2024-03-18T22:59:03.421637Z","shell.execute_reply":"2024-03-18T22:59:03.978633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comments:\n- It seems that there is only a moderate positive correlation between \"SkinThickess\" and \"Insulin\" with 0.44.","metadata":{}},{"cell_type":"markdown","source":"# STEP 2: Feature Engineering\n## 2.1 - Perform necessary operations for missing and outlier values. ","metadata":{}},{"cell_type":"markdown","source":"_Although there are no missing observations in the dataset, observations containing 0 values in variables like Glucose, Insulin, etc. may represent missing values. For example, a person's Glucose or Insulin value cannot be 0. Considering this, we can assign NaN to zero values in the relevant variables and then apply operations to missing values._","metadata":{}},{"cell_type":"code","source":"def missing_values_summary(dataframe, print_df=True, return_na_col_names=False,return_na_df=False):\n    print(\"---------------------------------------------\")\n    print(\"----- Missing Values Summary ----------------\")\n    print(\"---------------------------------------------\")\n    \n    na_cols = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    na_list = dataframe[na_cols].isnull().sum().sort_values(ascending=False)\n    na_ratios = (dataframe[na_cols].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n    na_df = pd.DataFrame(na_ratios).reset_index().rename(columns={\"index\": \"NA_Column\", 0: \"Ratio\"})\n    if print_df:\n        if len(na_df) == 0:\n            print(\"There is no missing values in the dataset.\")\n        else:\n            na_df\n    \n    if return_na_col_names:\n        return na_cols\n\n    if return_na_df:\n        return na_df\n#----------------------------------------------------------------------------------------------------------------------\ndef missing_values_table(dataframe, na_name=False):\n    print(\"---------------------------------------------\")\n    print(\"----- Missing Values Table ------------------\")\n    print(\"---------------------------------------------\")\n    \n    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])\n    missing_df\n    if na_name:\n        return na_columns\n#----------------------------------------------------------------------------------------------------------------------\ndef missing_vs_target_analysis(dataframe, target_var_name):\n    print(\"---------------------------------------------\")\n    print(\"----- Missing Values vs. Target Analysis ----\")\n    print(\"---------------------------------------------\")\n    \n    temp_df = dataframe.copy()\n    na_columns = missing_values_summary(temp_df, return_na_col_names=True)\n\n    for col in na_columns:\n        temp_df[col + \"_na_flag\"] = np.where(temp_df[col].isnull(), 1, 0)\n\n    na_flags = temp_df.loc[:, temp_df.columns.str.contains(\"_na_flag\")].columns\n\n    for col in na_flags:\n        print(pd.DataFrame({\"Target_Mean\": temp_df.groupby(col)[target_var_name].mean(),\n                            \"Count\": temp_df.groupby(col)[target_var_name].count()}))\n        print(\"----------------------------------------------------------------\")\n#----------------------------------------------------------------------------------------------------------------------\ndef missing_corr_analysis(dataframe, plot_show=True):\n    temp_df = dataframe.copy()\n    na_columns = missing_values_summary(temp_df, return_na_col_names=True)\n    for col in na_columns:\n        temp_df[col + \"_na\"] = np.where(temp_df[col].isnull(), 1, 0)\n    na_flags = temp_df.loc[:, temp_df.columns.str.contains(\"_na\")].columns\n    corr_missing = temp_df[na_flags].corr()\n    #print(corr_missing)\n    if plot_show:\n        sns.heatmap(corr_missing, cmap=\"RdBu\", annot=True, vmax=1, vmin=-1)\n        plt.show(block=True)\n#----------------------------------------------------------------------------------------------------------------------\ndef remove_outliers(dataframe, col_name, q1=0.25, q3=0.75):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name, q1, q3)\n    df_without_outliers = dataframe[~((df[col_name] < low_limit) | (dataframe[col_name] > up_limit))]\n    return df_without_outliers\n#----------------------------------------------------------------------------------------------------------------------\ndef winsorize_with_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name, q1, q3)\n    dataframe.loc[(dataframe[col_name] < low_limit), col_name] = low_limit\n    dataframe.loc[(dataframe[col_name] > up_limit), col_name] = up_limit\n#----------------------------------------------------------------------------------------------------------------------\ndef local_outlier_factor_analysis(dataframe, plot=False, return_scores= False, n_neighbors=20):\n    lof = LocalOutlierFactor(n_neighbors=n_neighbors)\n    lof.fit_predict(dataframe)\n    scores_neg = np.sort(lof.negative_outlier_factor_)\n    if plot:\n        pd.DataFrame(scores_neg).plot(stacked=True, xlim = [0,30], style=\".-\")\n        plt.show()\n    if return_scores:\n        return scores_neg","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-18T22:59:03.982864Z","iopub.execute_input":"2024-03-18T22:59:03.983412Z","iopub.status.idle":"2024-03-18T22:59:04.014709Z","shell.execute_reply.started":"2024-03-18T22:59:03.983354Z","shell.execute_reply":"2024-03-18T22:59:04.01331Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Copy Dataset","metadata":{}},{"cell_type":"code","source":"df_w = df.copy()","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:04.016233Z","iopub.execute_input":"2024-03-18T22:59:04.016838Z","iopub.status.idle":"2024-03-18T22:59:04.030799Z","shell.execute_reply.started":"2024-03-18T22:59:04.01679Z","shell.execute_reply":"2024-03-18T22:59:04.029541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Missing Values","metadata":{}},{"cell_type":"code","source":" #- assigning NaN of 0 values of \"Glucose, BloodPressure, SkinThickness, Insulin, BMI\" are corrected\nzero_removing_columns = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\"]\ndf_w[zero_removing_columns] = df_w[zero_removing_columns].replace(0, np.nan)\ndf_w","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:04.032542Z","iopub.execute_input":"2024-03-18T22:59:04.032882Z","iopub.status.idle":"2024-03-18T22:59:04.061007Z","shell.execute_reply.started":"2024-03-18T22:59:04.032853Z","shell.execute_reply":"2024-03-18T22:59:04.059863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#---------------------------------------------------------------------------------------------\n #- check missing values\nmissing_vs_target_analysis(df_w, target_label)\nprint(\"--------------------------------------------------------------------------------------\")\n#---------------------------------------------------------------------------------------------\nmissing_corr_analysis(df_w) #-> Significant correlation between SkinThickness and Insulin","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:04.062434Z","iopub.execute_input":"2024-03-18T22:59:04.062831Z","iopub.status.idle":"2024-03-18T22:59:04.544009Z","shell.execute_reply.started":"2024-03-18T22:59:04.062799Z","shell.execute_reply":"2024-03-18T22:59:04.543156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comments:\n- It seems that there is a moderate positive correlation between \"SkinThickess\" and \"Insulin\" with 0.66 for missing values.","metadata":{}},{"cell_type":"markdown","source":"#### Missing Values Solutions","metadata":{}},{"cell_type":"code","source":" #- assign means of Pregnancies for each\nfor col in num_cols:\n    df_w[col].fillna(df_w.groupby(\"Pregnancies\")[col].transform(\"mean\"), inplace=True)\n\ndf_w","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:04.545677Z","iopub.execute_input":"2024-03-18T22:59:04.546263Z","iopub.status.idle":"2024-03-18T22:59:04.574695Z","shell.execute_reply.started":"2024-03-18T22:59:04.546224Z","shell.execute_reply":"2024-03-18T22:59:04.573403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comments:\n- All missing values are filled by their means considering Pregnancy count.","metadata":{}},{"cell_type":"markdown","source":"#### Outliers","metadata":{}},{"cell_type":"code","source":" #- box plots\nfor col in df_w.columns:\n    if col != target_label:\n        sns.boxplot(x=df_w[col],)\n        plt.show(block=True)\n #- analysis of categorical variables after corrections\nfor col in cat_cols:\n    print(f\"{col} ---------------------------------------------------------------------------\")\n    df_grouped = df.groupby(col).agg({\"Outcome\": [\"mean\", \"count\"]})\n    print(df_grouped.sort_values(by=(\"Outcome\", \"mean\"), ascending=False))\n    print(\"----------------------------------------------------------------------------------\")\n #- analysis of numerical variables after corrections\nfor col in num_cols:\n    print(f\"{col} ---------------------------------------------------------------------------\")\n    df_grouped = df.groupby(\"Outcome\", group_keys=False).agg({col: [\"mean\", \"min\", \"max\"]})\n    print(df_grouped.sort_values(by=(col, \"mean\"), ascending=False))\n    print(\"----------------------------------------------------------------------------------\")\n #- check if any outlier exists\nfor col in df.columns:\n    check_if_outlier_exists(df, col, q1=0.05, q3=0.95) #--> seem proper as Q1 and Q3\n#---------------------------------------------------------------------------------------------\n #- local factor analysis\nscores = local_outlier_factor_analysis(df_w, plot=True, return_scores=True) #-> 5. value seems proper (-1.80269)\ndf_w[scores < scores[5]] #-> only 5 values which can be eliminated (5/768)\ndf_w[scores < scores[5]].describe().T\n","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:04.576044Z","iopub.execute_input":"2024-03-18T22:59:04.577045Z","iopub.status.idle":"2024-03-18T22:59:07.066869Z","shell.execute_reply.started":"2024-03-18T22:59:04.576985Z","shell.execute_reply":"2024-03-18T22:59:07.065637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Outliers Solutions\n","metadata":{}},{"cell_type":"code","source":"#---------------------------------------------------------------------------------------------\n #- winsorizing outliers\nfor col in df.columns:\n    winsorize_with_thresholds(df_w, col, q1=0.1, q3=0.9)\n#---------------------------------------------------------------------------------------------\n #- eliminating outliers according to LOF\ndf_w = df_w.drop(index=df_w[scores < scores[5]].index)\nprint(f\"New dataset size: {df_w.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:07.068895Z","iopub.execute_input":"2024-03-18T22:59:07.069669Z","iopub.status.idle":"2024-03-18T22:59:07.101453Z","shell.execute_reply.started":"2024-03-18T22:59:07.069623Z","shell.execute_reply":"2024-03-18T22:59:07.100441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comments:\n- 0 values of \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\" are corrected as NaN.\n- There is a correlation of missing values between SkinThickness and Insulin (0.66).\n- Missing values are filled based on Pregnancies group Means. KNN Imputer has not been chosen as Insulin (48%) and SkinThickness (30%) are significantly empty.\n- Q1 and Q3 for Outliers are selected as 0.1 and 0.9 as it does not touch that much to many outliers but insulin.\n-   Winsorisation has been applied.\n- 5 observation of 768 are removed from dataset which are found via LOF.","metadata":{}},{"cell_type":"markdown","source":"## 2.2 - Create new variables.","metadata":{}},{"cell_type":"code","source":"#---------------------------------------------------------------------------------------------\nrare_analyzer(df, target_label, forNumericals=True)\n#---------------------------------------------------------------------------------------------\ndf_w[\"Pregnancies_levels\"] = pd.cut(df_w[\"Pregnancies\"], bins=[0,3,6,13,17],labels=[\"Ordinary\",\"More than Ordinary\",\"Rare\",\"Extraordinary\"])\ndf_w[\"BMI_levels\"] = pd.cut(df_w[\"BMI\"], bins=[0,18.5,24.99999,29.99999,90], labels=[\"Underweight\",\"Normal Weight\",\"Overweight\",\"Obese\"])\ndf_w[\"Age_levels\"] = pd.cut(df[\"Age\"], bins=[0,10,20,30,40,50,60,70,80,90,100,110,120])\ndf_w[\"Glucose_levels\"] = pd.cut(df[\"Glucose\"], bins=[0,115,180,280,380,1000], labels=[\"Excellent\",\"Good\",\"Action Suggested\",\"See Doctor\",\"Dangerous\"])\ndf_w\n","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:07.102802Z","iopub.execute_input":"2024-03-18T22:59:07.103412Z","iopub.status.idle":"2024-03-18T22:59:07.216155Z","shell.execute_reply.started":"2024-03-18T22:59:07.103366Z","shell.execute_reply":"2024-03-18T22:59:07.215003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comments:\n- from Pregnancies, (0-3), (4-6), (7-13), (14-17) are created.\n- from BMI (<0.185)-> Underweight, (0.185-0.249999)-> Normal Weight, (0.25-0.2999999)-> Overweight, (> 30)-> Obese\n- from Age (0,10,20,30,40,50,60,70,80,90,100,110,120)\n- form Glucose (<150), (150-199),(200-249),(250-299),(300-349), (>=350)","metadata":{}},{"cell_type":"markdown","source":"### 2.3 - Perform encoding operations.","metadata":{}},{"cell_type":"code","source":"def label_encoder_binary(dataframe, return_col_names=True, return_encoded_dataframe=False):\n    if return_encoded_dataframe:\n        return_col_names = False\n    df_ = dataframe.copy()\n    binary_columns = []\n    label_encoder = LabelEncoder()\n    binary_columns = [col for col in df_.columns if df_[col].dtype not in [int, float] and df_[col].nunique() == 2]\n    if len(binary_columns) > 0:\n        for col in binary_columns:\n            df_[col] = label_encoder.fit_transform(df_[col])\n    if return_col_names:\n        return binary_columns\n    if return_encoded_dataframe:\n        return df_\n#-----------------------------------------------------------------------------------------------------------------------\ndef one_hot_encoder(dataframe, categorical_columns, drop_first=True, return_dataframe=False, print_df=False):\n    df_ = dataframe.copy()\n    df_ = pd.get_dummies(df_, columns=categorical_columns, drop_first=drop_first)\n    \n    if print_df:\n        print(df_.head())\n    if return_dataframe:\n        return df_","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:07.217587Z","iopub.execute_input":"2024-03-18T22:59:07.218158Z","iopub.status.idle":"2024-03-18T22:59:07.228111Z","shell.execute_reply.started":"2024-03-18T22:59:07.218122Z","shell.execute_reply":"2024-03-18T22:59:07.226902Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#---------------------------------------------------------------------------------------------\n #- use one hot encoder\nohe_cols = [\"Pregnancies_levels\",\"BMI_levels\",\"Age_levels\",\"Glucose_levels\",\"Pregnancies\"]\ndf_w = one_hot_encoder(df_w,ohe_cols, return_dataframe=True)\ndf_w","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:07.230087Z","iopub.execute_input":"2024-03-18T22:59:07.23112Z","iopub.status.idle":"2024-03-18T22:59:07.270991Z","shell.execute_reply.started":"2024-03-18T22:59:07.231068Z","shell.execute_reply":"2024-03-18T22:59:07.269796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Comments:\n- As there is no binary variable except target, one hot encoder has been applied.","metadata":{}},{"cell_type":"markdown","source":"## 2.4 - Standardize numerical variables.","metadata":{}},{"cell_type":"code","source":"#---------------------------------------------------------------------------------------------\nstandard_cols = [col for col in df_w.columns if col not in ohe_cols]\nscaler = StandardScaler()\nscaler.fit_transform(df_w[standard_cols])\ndf_w","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:07.272464Z","iopub.execute_input":"2024-03-18T22:59:07.272807Z","iopub.status.idle":"2024-03-18T22:59:07.311789Z","shell.execute_reply.started":"2024-03-18T22:59:07.272779Z","shell.execute_reply":"2024-03-18T22:59:07.310514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# STEP 3: Modelling","metadata":{}},{"cell_type":"markdown","source":"Now, we test our processed data on two different models.","metadata":{}},{"cell_type":"markdown","source":"## 3.1 - K-Nearest Neighbors Model","metadata":{}},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, mean_squared_error\nfrom sklearn.model_selection import train_test_split, cross_val_score\n\ndff = df.copy()\ndff.dropna(inplace=True)\n\nX = dff.drop(target_label, axis=1)\ny = dff[target_label]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n\nknn = KNeighborsClassifier(n_neighbors=5)\nkfold = 10\nscores = cross_val_score(knn, X_train, y_train, cv=kfold)\n\nprint(\"----- RAW DATASET RESULTS -----\")\n#print(f\"--> Scores: {scores}\")\nprint(\"--------------------------------------------------------------------------------------\")\nprint(f\"KNN with {kfold}-Fold CV Score: {scores.mean():.4f}\")\nprint(\"--------------------------------------------------------------------------------------\")\nprint(\"\\n\")\n\n#---------------------------------------------------------------------------------------------\nX = df_w.drop(target_label, axis=1)\ny = df_w[target_label]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n\nknn = KNeighborsClassifier(n_neighbors=5)\nkfold = 10\nscores = cross_val_score(knn, X_train, y_train, cv=kfold)\n\nprint(\"----- PROCESSED DATASET RESULTS -----\")\n#print(f\"--> Scores: {scores}\")\nprint(\"--------------------------------------------------------------------------------------\")\nprint(f\"KNN with {kfold}-Fold CV Score: {scores.mean():.4f}\")\nprint(\"--------------------------------------------------------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:07.31346Z","iopub.execute_input":"2024-03-18T22:59:07.314218Z","iopub.status.idle":"2024-03-18T22:59:07.593485Z","shell.execute_reply.started":"2024-03-18T22:59:07.31416Z","shell.execute_reply":"2024-03-18T22:59:07.592227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 - Random Forest Classifier Model","metadata":{}},{"cell_type":"code","source":"def feature_importance_levels (model, features, num=len(X), save=False):\n    feature_imp = pd.DataFrame({'Value': model.feature_importances_, 'Feature': features.columns})\n    plt.figure(figsize=(10, 10))\n    sns.set(font_scale=1)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\",ascending=False)[0: num])\n    plt.title('Features') \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:07.595028Z","iopub.execute_input":"2024-03-18T22:59:07.596199Z","iopub.status.idle":"2024-03-18T22:59:07.605268Z","shell.execute_reply.started":"2024-03-18T22:59:07.59615Z","shell.execute_reply":"2024-03-18T22:59:07.604204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\ndff = df.copy()\ndff.dropna(inplace=True)\n\ny = df[\"Outcome\"]\nX = df.drop([\"Outcome\"], axis=1)\n\nscores = []\nkfold = 10\n\nfor _ in range(kfold):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n    rf = RandomForestClassifier().fit(X_train, y_train)\n    y_pred = rf.predict(X_test)\n    scores.append(accuracy_score(y_pred, y_test))\n\nprint(\"----- RAW DATASET RESULTS -----\")\n#print(f\"--> Scores: {scores}\")\nprint(\"--------------------------------------------------------------------------------------\")\nprint(f\"Random Forest with {kfold}-Fold CV Score: {np.mean(scores):.4f}\")\nprint(\"--------------------------------------------------------------------------------------\")\nprint(\"\\n\")\nfeature_importance_levels(rf, X_train)\n#---------------------------------------------------------------------------------------------\ny = df_w[\"Outcome\"]\nX = df_w.drop([\"Outcome\"], axis=1)\n\nscores = []\nkfold = 10\n\nfor _ in range(kfold):\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n    rf = RandomForestClassifier().fit(X_train, y_train)\n    y_pred = rf.predict(X_test)\n    scores.append(accuracy_score(y_pred, y_test))\n\nprint(\"----- PROCESSED DATASET RESULTS -----\")\n#print(f\"--> Scores: {scores}\")\nprint(\"--------------------------------------------------------------------------------------\")\nprint(f\"Random Forest with {kfold}-Fold CV Score: {np.mean(scores):.4f}\")\nprint(\"--------------------------------------------------------------------------------------\")\nfeature_importance_levels(rf, X_train)","metadata":{"execution":{"iopub.status.busy":"2024-03-18T22:59:07.611743Z","iopub.execute_input":"2024-03-18T22:59:07.612421Z","iopub.status.idle":"2024-03-18T22:59:14.995382Z","shell.execute_reply.started":"2024-03-18T22:59:07.612372Z","shell.execute_reply":"2024-03-18T22:59:14.994052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"More models can be applied. As feature engineering is the main focus of this project, only 2 models is applied for demonstration purposes.","metadata":{}},{"cell_type":"markdown","source":"---\n### I hope you found the analysis insightful and informative! \n### Your feedback is greatly appreciated, and I welcome any suggestions for improvement. Feel free to reach out with any questions or comments.\n---","metadata":{}}]}